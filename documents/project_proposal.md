# CS 225 Data Structures

## Project Proposal (rohitc2-ssohai20-adamjn3-nconner2)

1. **Leading Question:** We plan to use a dataset from Stanford University called “Social Network: Reddit Hyperlink Network”, it consists of a hyperlink network in between subreddits. Using this dataset, we would like to use Google’s PageRank algorithm in order to organize subreddits by their importance. We are planning on creating a general search tool that will allow anyone to determine the most important subreddits.
 
2. **Dataset Acquisition and Processing:** We have chosen to use the reddit hyperlink dataset from Stanford University. The dataset uses tab separated value (.tsv) file format. Each line consists of six attributes: source subreddit, target subreddit, post id, timestamp, post label, and post properties. The only data we care about is the source and target subreddits which are subreddits and hyperlinked subreddits, respectfully. We will restructure the lines of the .tsv file so that the first element is the source subreddit and the following elements are all of it’s target subreddits. This will resolve duplicate source-target pairs and make creating a graph much simpler. The reason we only need the source and target subreddits is because this is the only real data that is used for the PageRank algorithm. The graph we will be creating is directed where each node will represent a source subreddit and will contain a vector of pointers to it’s target nodes as well as an integer attribute to record the number of visits to the node. The pointers represent the edges in the graph. These nodes will be stored in a vector which will be sorted by number of visits at the end of the PageRank algorithm. If our dataset has errors or missing data, we will ignore the data as it will have a negligent impact on accuracy of the algorithm.
 
3. **Graph Algorithms:** We will be using a directed graph in order to represent our data, the nodes will be the subreddits, and the edges represent a link from one subreddit to another.We will implement the PageRank algorithm to rank the various subreddits from a value of 0 to 1 where 1 represents the highest probability that a random user will reach the subreddit after clicking through a series of hyperlinks. We will then sort the subreddit nodes by their rankings using the merge sort algorithm; the merge sort algorithm will take in an unsorted vector of pointers to the subreddit node objects and will output a sorted – by ranking/popularity – vector of pointers to subreddit nodes. The PageRank inputs will include the subreddit nodes and iteration length and will have no outputs; it will calculate the rankings and adjust the subreddit node objects accordingly. If implemented correctly and efficiently, the PageRank algorithm should have a worst case time complexity of O(logn) and the merge sort algorithm should have a worst case time complexity of O(nlogn). Lastly, we will implement a DFS/BFS traversal of our directed graph structure that contains the subreddit nodes. The time complexity of the BFS/DFS traversal will be O(n).
 
4. **Timeline:** There are a lot of tasks that are necessary for this project to be successful. We have already begun brainstorming a plan of how to implement the project and designate different tasks to each group member. Our first task will be to efficiently retrieve and process all of the data that we need, this will be done in Week 1. The next step is to create the directed graph structure that we will be using and implement the PageRank algorithm in order to determine the probability for each subreddit relative to the others, this will be done in Week 2. Afterwards, we will implement the merge sort algorithm in order to sort the percentages of each subreddit to find the most important subreddits, this will be done in Week 3. Lastly, we will implement the BFS/DFS traversal on our graph structure, this will be done in Week 4. Once these basic functions of our project are working, we will optimize our code and add extra functionality/features, this will be done in Week 5.
 
 
